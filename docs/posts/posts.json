[
  {
    "path": "posts/2022-02-20-dataproject1/",
    "title": "Data Project: Binary Logistic Regression",
    "description": "An example of my data science work where I performed binary logistic regression on Florida Palmettos data.",
    "author": [
      {
        "name": "Sarah Hamilton",
        "url": {}
      }
    ],
    "date": "2022-02-20",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nData Exploration & Visualization\nBinary Logistic Regression\nModel 1\nModel 2\n\nModel Selection\nComparing AICs\n10-Fold Cross Validation\n\nModel Success\n\nIntroduction\nIn the following code, I perform binary logistic regression (BLR) on data related to Florida palmettos in order to determine which of two models better classifies the species of palmettos. I first performed BLR on two different models, and then visualized the results and identified the better performing model. The data used comes from the Environmental Data Initiative, and contains identifying information about the palmettos such as the year, species, site, and other parameters.\nData Citation: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5\n\n\nhide\n\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\n\n#install necessary packages\nlibrary(tidyverse)\nlibrary(GGally) \nlibrary(broom) \nlibrary(jtools) \nlibrary(caret) \nlibrary(AICcmodavg) \nlibrary(here)\nlibrary(patchwork)\nlibrary(kableExtra)\n\n\n\nData Exploration & Visualization\nI plotted the data below to determine which variables will best predict the palmetto species.\n\n\nhide\n\n#read in the data\npalmetto <- read_csv(here(\"palmetto.csv\"))\n\n#species = 1 --> serenoa repens\n#species = 2 --> sabal etonia\n\n#explore differences in height, canopy length, canopy width, and green leaves for the two species using ggpairs\npalmetto_sub <- palmetto %>%\n  select(species, height:green_lvs) %>%\n  mutate(species = case_when( #rename the species to their scientific names \n    species == 1 ~ \"Serenoa repens\",\n    species == 2 ~ \"Sabal etonia\"\n  )) %>%\n  drop_na()\n\npairs_exploratory_plot <- palmetto_sub %>%\n  ggpairs(aes(color = species))\n\n#pairs_exploratory_plot #use to output the exploratory ggpairs plot\n\n#Height is very similar between the species, so plot green leaves vs. length and green leaves vs. width \nleaves_length_plot <- ggplot(data = palmetto_sub, aes(x = length, y = green_lvs)) +\n  geom_point(aes(color = species)) +\n  theme_minimal() +\n  labs(x = \"Length (cm)\", y = \"No. of Green Leaves\") +\n  scale_color_manual(values = c(\"#88315c\", \"#5799a8\"))\n\n#leaves_length_plot\n\nleaves_width_plot <- ggplot(data = palmetto_sub, aes(x = width, y = green_lvs)) +\n  geom_point(aes(color = species)) +\n  theme_minimal() +\n  labs(x = \"Width (cm)\", y = \"No. of Green Leaves\") +\n  scale_color_manual(values = c(\"#88315c\", \"#5799a8\")) +\n  theme(legend.position = \"none\")\n\n#leaves_width_plot\n\nlength_width_plot <- ggplot(data = palmetto_sub, aes(x = width, y = length)) +\n  geom_point(aes(color = species)) +\n  theme_minimal() +\n  labs(x = \"Width (cm)\", y = \"Length (cm)\") +\n  scale_color_manual(values = c(\"#88315c\", \"#5799a8\")) +\n  theme(legend.position = \"none\")\n\n#length_width_plot\n\n(length_width_plot | leaves_width_plot | leaves_length_plot) +\n  plot_annotation(caption = str_wrap(\"Figure 1. The top graph plots the length of the palmetto versus the width, the bottom left graph plots the number of green leaves on the palmetto versus the width, and the bottom right graph plots the number of green leaves on the palmetto versus the length. The color indicates the palmetto species.\"),\n                  theme = theme(plot.caption = element_text(hjust = 0.5)))\n\n\n\n\nThe exploratory plots show us that there is the most variation between species in the number of green leaves that each has. They show that the species do not vary much from each other for length and width. Therefore, the number of green leaves will likely be the most helpful variable for classifying species.\nBinary Logistic Regression\nModel 1\nThe first model I tested is species as a function of height, length, width, and number of green leaves.\n\n\nhide\n\n#make species a factor \npalmetto_sub$species <- as.factor(palmetto_sub$species)\n#Levels: Sabal etonia = 0, Serenoa repens = 1\n\n#BLR on Model 1: Plant type as function of plant height, canopy length, canopy width and green leaves.\nf1 <- species ~ height + length + width + green_lvs\n\npalmetto_blr1 <- glm(formula = f1,\n                     data = palmetto_sub,\n                     family = 'binomial')\n\n#summary(palmetto_blr1)\nblr1_tidy <- broom::tidy(palmetto_blr1)\n#blr1_tidy\n\n\n\n\n\nhide\n\n#make a table to predict the species of each point for model 1\nblr1_fitted <- palmetto_blr1 %>%\n  broom::augment(type.predict = 'response')\n\n#plot the probability \nggplot(data = blr1_fitted, aes(x = green_lvs, y = .fitted)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(aes(color = species), se = FALSE) +\n  labs(x = \"No. of Green Leaves\", y = \"Probability of outcome 'Serenoa repens'\") +\n  theme_minimal()\n\n\n\n\n\n\nhide\n\n#visualize model outcomes for model 1\neff_1 <- effect_plot(palmetto_blr1,\n            pred = green_lvs,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\neff_2 <- effect_plot(palmetto_blr1,\n            pred = length,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\neff_3 <- effect_plot(palmetto_blr1,\n            pred = width,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\neff_4 <- effect_plot(palmetto_blr1,\n            pred = height,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\n(eff_1 | eff_2 | eff_3 | eff_4)\n\n\n\n\nModel 2\nThe second model I tested is species as a function of height, width, and number of green leaves.\n\n\nhide\n\n#BLR on Model 2: Plant type as function of  plant height, canopy width and green leaves\n\nf2 <- species ~ height + width + green_lvs\n\npalmetto_blr2 <- glm(formula = f2,\n                     data = palmetto_sub,\n                     family = 'binomial')\n\n#summary(palmetto_blr2)\nblr2_tidy <- broom::tidy(palmetto_blr2)\n#blr2_tidy\n\n\n\n\n\nhide\n\n#make a table to predict the species of each point for model 2\nblr2_fitted <- palmetto_blr2 %>%\n  broom::augment(type.predict = 'response')\n\n#plot the probability \nggplot(data = blr2_fitted, aes(x = green_lvs, y = .fitted)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(aes(color = species), se = FALSE) +\n  labs(x = \"No. of Green Leaves\", y = \"Probability of outcome 'Serenoa repens'\") +\n  theme_minimal()\n\n\n\n\n\n\nhide\n\n#visualize model outcomes for model 2\neff_5 <- effect_plot(palmetto_blr2,\n            pred = green_lvs,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\neff_6 <- effect_plot(palmetto_blr2,\n            pred = width,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\neff_7 <- effect_plot(palmetto_blr2,\n            pred = height,\n            interval = TRUE,\n            y.label = \"Probability of 'Serenoa repens'\")\n\n(eff_5 | eff_6 | eff_7)\n\n\n\n\nModel Selection\nTo answer the question of which model is better, I compared the AICs of the models and then performed 10-fold cross validation to see which model performed better.\nComparing AICs\n\n\nhide\n\naic_models <- AICcmodavg::aictab(list(palmetto_blr1, palmetto_blr2))\n\n\n\nModel 1 has a lower AICc (5195) than model 2 (5987), indicating that it may be the better model. The difference in the AICc values is significant (Delta AICc = 793).\n10-Fold Cross Validation\n\n\nhide\n\nset.seed(21)\n\ntr_ctrl <- trainControl(method = \"repeatedcv\", number = 10, repeats = 10)\n\n#train the model \nmodel1 <- train(f1, data = palmetto_sub,\n                method = 'glm', family = 'binomial',\n                trControl = tr_ctrl)\n\n#model1\n\nmodel2 <- train(f2, data = palmetto_sub,\n                method = 'glm', family = 'binomial',\n                trControl = tr_ctrl)\n\n#model2\n\n\n\nThe results of the 10-fold cross validation returned an accuracy of 92% for Model 1 and an accuracy of 90% for Model 2. These values indicate slightly higher accuracy for Model 1, indicating that Model 1 is a slightly better model, which is also confirmed by Model 1 having a lower AIC value.\n\n\nhide\n\n#make a table of results of BLR models\n\nblr1_tidy$p.value <- ifelse(blr1_tidy$p.value < .001, \n                            paste(\"< .001\"))\n\nblr1_tidy %>%\n  kable(col.names = c(\"Term\", \"Estimate\", \"Std. Error\", \"Statistic\", \"P Value\"),\n        digits = 2,\n        caption = \"Table 1. BLR Model 1 Results\") %>%\n  kable_styling(full_width = FALSE)\n\n\n\nTable 1: Table 1. BLR Model 1 Results\n\n\nTerm\n\n\nEstimate\n\n\nStd. Error\n\n\nStatistic\n\n\nP Value\n\n\n(Intercept)\n\n\n-3.23\n\n\n0.14\n\n\n-22.71\n\n\n< .001\n\n\nheight\n\n\n0.03\n\n\n0.00\n\n\n12.67\n\n\n< .001\n\n\nlength\n\n\n-0.05\n\n\n0.00\n\n\n-24.56\n\n\n< .001\n\n\nwidth\n\n\n-0.04\n\n\n0.00\n\n\n-18.78\n\n\n< .001\n\n\ngreen_lvs\n\n\n1.91\n\n\n0.04\n\n\n49.11\n\n\n< .001\n\n\nhide\n\n# blr2_tidy %>%\n#   kable(col.names = c(\"Term\", \"Estimate\", \"Std. Error\", \"Statistic\", \"P Value\"),\n#         digits = 2,\n#         caption = \"Table 2. BLR Model 2 Results\") %>%\n#   kable_styling(full_width = FALSE)\n\n\n\nFinal Model 1 Equation:\n\n\nhide\n\n#output the final equation \nequatiomatic::extract_eq(model = palmetto_blr1, use_coefs = TRUE)\n\n\n\\[\n\\log\\left[ \\frac { \\widehat{P( \\operatorname{species} = \\operatorname{Serenoa\\ repens} )} }{ 1 - \\widehat{P( \\operatorname{species} = \\operatorname{Serenoa\\ repens} )} } \\right] = -3.23 + 0.03(\\operatorname{height}) - 0.05(\\operatorname{length}) - 0.04(\\operatorname{width}) + 1.91(\\operatorname{green\\_lvs})\n\\]\n\nModel Success\n\n\nhide\n\n#evaluate how successful the model is at classifying the two palmetto types\n\nblr1_predict <- blr1_fitted %>%\n  mutate(predicted = case_when(\n    .fitted >= 0.5 ~ \"Serenoa repens\",\n    .fitted < 0.5 ~ \"Sabal etonia\"\n  )) %>%\n  mutate(correct = case_when(\n    species == predicted ~ \"Y\",\n    species != predicted ~ \"N\"\n  ))\n\naccuracy_counts <- blr1_predict %>%\n  janitor::tabyl(species, correct)\n\naccuracy_counts <- accuracy_counts %>%\n  mutate(\"% Correct\" = round(100*accuracy_counts$Y/(accuracy_counts$Y+accuracy_counts$N),2)) %>%\n  kable(col.names = c(\"Species\", \"Incorrectly Classified\", \"Correctly Classified\", \"% Correctly Classified\"),\n        digits = 1,\n        caption = \"Table 2. Classification accuracy results from BLR Model 1\") %>%\n  kable_styling(full_width = FALSE)\n\naccuracy_counts\n\n\n\nTable 2: Table 2. Classification accuracy results from BLR Model 1\n\n\nSpecies\n\n\nIncorrectly Classified\n\n\nCorrectly Classified\n\n\n% Correctly Classified\n\n\nSabal etonia\n\n\n454\n\n\n5701\n\n\n92.6\n\n\nSerenoa repens\n\n\n564\n\n\n5548\n\n\n90.8\n\n\nModel 1 predicted the Sabal etonia species with slightly more accuracy than the Serena repens species, but it predicted both with greater than 90% accuracy.\n\n\n\n",
    "preview": "posts/2022-02-20-dataproject1/dataproject1_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-03-10T09:54:49-08:00",
    "input_file": "dataproject1.knit.md"
  },
  {
    "path": "posts/2022-02-20-dataproject2/",
    "title": "Data Project: Nonlinear Least Squares Regression",
    "description": "An example of my data science work where I performed nonlinear least squares regression on lizard data.",
    "author": [
      {
        "name": "Sarah Hamilton",
        "url": {}
      }
    ],
    "date": "2022-02-20",
    "categories": [],
    "contents": "\nLink to Nonlinear Least Squares Regression\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-20T16:41:35-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-20-dataproject3/",
    "title": "Data Project: Principal Component Analysis",
    "description": "An example of my data science work where I performed a principal component analysis of climatic data.",
    "author": [
      {
        "name": "Sarah Hamilton",
        "url": {}
      }
    ],
    "date": "2022-02-20",
    "categories": [],
    "contents": "\nLink to Principal Component Analysis\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-20T16:41:45-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-20-dataproject4/",
    "title": "Data Project: Hierarchical Clustering",
    "description": "An example of my data science work where I performed hierarchical clustering on watershed data.",
    "author": [
      {
        "name": "Sarah Hamilton",
        "url": {}
      }
    ],
    "date": "2022-02-20",
    "categories": [],
    "contents": "\nLink to Hierarchical Clustering\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-20T16:42:03-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-21-welcome/",
    "title": "Welcome to my blog!",
    "description": "An introduction to my blog.",
    "author": [
      {
        "name": "Sarah Hamilton",
        "url": {}
      }
    ],
    "date": "2022-01-21",
    "categories": [],
    "contents": "\nHello! This blog will contain updates from my data science adventures, such as cool visualizations I have made or other fun updates.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-20T16:27:52-08:00",
    "input_file": {}
  }
]
